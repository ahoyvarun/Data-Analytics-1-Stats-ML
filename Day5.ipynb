{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest, RFE\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Food_and_Nutrition__.csv')\n",
        "\n",
        "# Step 1: Handling Missing Values\n",
        "print(\"Missing Values Before Imputation:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Impute numerical features with the mean\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "data[numerical_cols] = num_imputer.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Impute categorical features with the mode\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "data[categorical_cols] = cat_imputer.fit_transform(data[categorical_cols])\n",
        "\n",
        "print(\"\\nMissing Values After Imputation:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Step 2: Scaling Data\n",
        "scaler = StandardScaler()\n",
        "normalizer = MinMaxScaler()\n",
        "\n",
        "# Standardization\n",
        "data_std = data.copy()\n",
        "data_std[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Normalization\n",
        "data_norm = data.copy()\n",
        "data_norm[numerical_cols] = normalizer.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Step 3: Handling Noise\n",
        "# Inject random noise into the \"Calories\" column\n",
        "data_noisy = data.copy()\n",
        "np.random.seed(42)\n",
        "data_noisy['Calories'] += np.random.normal(0, 50, size=len(data))\n",
        "\n",
        "# Smoothing using moving average\n",
        "data_noisy['Calories_Smoothed'] = data_noisy['Calories'].rolling(window=5).mean()\n",
        "data_noisy['Calories_Smoothed'].fillna(data_noisy['Calories'], inplace=True)\n",
        "\n",
        "# Step 4: Handling Outliers\n",
        "# Detect outliers using Z-scores\n",
        "data['Z_Score'] = zscore(data['Calories'])\n",
        "outliers = data[np.abs(data['Z_Score']) > 3]\n",
        "\n",
        "print(f\"\\nNumber of Outliers Detected: {len(outliers)}\")\n",
        "\n",
        "# Remove outliers\n",
        "data_cleaned = data[np.abs(data['Z_Score']) <= 3].drop(columns=['Z_Score'])\n",
        "\n",
        "# Step 5: Feature Selection\n",
        "# Filter Method: Correlation with target (e.g., Disease)\n",
        "# Select only numerical features for correlation calculation\n",
        "correlation = data_cleaned.select_dtypes(include=['number']).corr()  # Include only numerical features\n",
        "\n",
        "print(\"\\nCorrelation with Target Variable (Disease):\")\n",
        "# Check if 'Daily Calorie Target' is in the columns before accessing it\n",
        "if 'Daily Calorie Target' in correlation.columns:\n",
        "    print(correlation['Daily Calorie Target'].sort_values(ascending=False))\n",
        "else:\n",
        "    print(\"Target variable 'Daily Calorie Target' not found in numerical columns.\")\n",
        "\n",
        "# Wrapper Method: Recursive Feature Elimination (RFE)\n",
        "X = data_cleaned[numerical_cols]\n",
        "y = data_cleaned['Disease']\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "rfe = RFE(log_reg, n_features_to_select=5)\n",
        "rfe.fit(X, y)\n",
        "\n",
        "print(\"\\nSelected Features by RFE:\")\n",
        "print(X.columns[rfe.support_])\n",
        "\n",
        "# Embedded Method: Lasso Regression\n",
        "# Convert target variable to numerical using Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()  # Create a LabelEncoder object\n",
        "y_encoded = le.fit_transform(y)  # Fit and transform the target variable\n",
        "\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X, y_encoded)  # Use the encoded target variable\n",
        "lasso_coefficients = pd.Series(lasso.coef_, index=X.columns)\n",
        "\n",
        "print(\"\\nLasso Regression Feature Importance:\")\n",
        "print(lasso_coefficients[lasso_coefficients != 0].sort_values(ascending=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8srHJXd1KYC",
        "outputId": "56ed32a3-0243-4596-9c17-337ba5591264"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Before Imputation:\n",
            "Ages                    0\n",
            "Gender                  0\n",
            "Height                  0\n",
            "Weight                  0\n",
            "Activity Level          0\n",
            "Dietary Preference      0\n",
            "Daily Calorie Target    0\n",
            "Protein                 0\n",
            "Sugar                   0\n",
            "Sodium                  0\n",
            "Calories                0\n",
            "Carbohydrates           0\n",
            "Fiber                   0\n",
            "Fat                     0\n",
            "Breakfast Suggestion    0\n",
            "Lunch Suggestion        0\n",
            "Dinner Suggestion       0\n",
            "Snack Suggestion        0\n",
            "Disease                 0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values After Imputation:\n",
            "Ages                    0\n",
            "Gender                  0\n",
            "Height                  0\n",
            "Weight                  0\n",
            "Activity Level          0\n",
            "Dietary Preference      0\n",
            "Daily Calorie Target    0\n",
            "Protein                 0\n",
            "Sugar                   0\n",
            "Sodium                  0\n",
            "Calories                0\n",
            "Carbohydrates           0\n",
            "Fiber                   0\n",
            "Fat                     0\n",
            "Breakfast Suggestion    0\n",
            "Lunch Suggestion        0\n",
            "Dinner Suggestion       0\n",
            "Snack Suggestion        0\n",
            "Disease                 0\n",
            "dtype: int64\n",
            "\n",
            "Number of Outliers Detected: 6\n",
            "\n",
            "Correlation with Target Variable (Disease):\n",
            "Daily Calorie Target    1.000000\n",
            "Calories                0.817877\n",
            "Fat                     0.719886\n",
            "Protein                 0.676428\n",
            "Sodium                  0.676428\n",
            "Fiber                   0.648173\n",
            "Sugar                   0.648173\n",
            "Carbohydrates           0.648173\n",
            "Weight                  0.282485\n",
            "Height                  0.252708\n",
            "Ages                   -0.155865\n",
            "Name: Daily Calorie Target, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b75e59629b8d>:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data_noisy['Calories_Smoothed'].fillna(data_noisy['Calories'], inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected Features by RFE:\n",
            "Index(['Ages', 'Height', 'Protein', 'Carbohydrates', 'Fat'], dtype='object')\n",
            "\n",
            "Lasso Regression Feature Importance:\n",
            "Carbohydrates           0.002190\n",
            "Weight                  0.002106\n",
            "Daily Calorie Target    0.001024\n",
            "Calories                0.000721\n",
            "Height                 -0.001626\n",
            "Ages                   -0.001780\n",
            "Protein                -0.017276\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}